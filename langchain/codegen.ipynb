{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (0.0.235)\n",
      "Requirement already satisfied: deeplake in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (3.6.11)\n",
      "Requirement already satisfied: openai in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (0.27.8)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.4.0-cp38-cp38-win_amd64.whl (635 kB)\n",
      "     -------------------------------------- 635.3/635.3 kB 1.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from langchain) (2.0.18)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from langchain) (0.5.9)\n",
      "Requirement already satisfied: langsmith<0.0.8,>=0.0.7 in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from langchain) (0.0.7)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from langchain) (1.24.4)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from langchain) (1.10.11)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from deeplake) (10.0.0)\n",
      "Requirement already satisfied: boto3 in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from deeplake) (1.28.4)\n",
      "Requirement already satisfied: click in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from deeplake) (8.1.5)\n",
      "Requirement already satisfied: pathos in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from deeplake) (0.3.0)\n",
      "Requirement already satisfied: humbug>=0.3.1 in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from deeplake) (0.3.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from deeplake) (4.65.0)\n",
      "Requirement already satisfied: numcodecs in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from deeplake) (0.11.0)\n",
      "Requirement already satisfied: pyjwt in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from deeplake) (2.7.0)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Downloading regex-2023.6.3-cp38-cp38-win_amd64.whl (268 kB)\n",
      "     -------------------------------------- 268.1/268.1 kB 1.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from pydantic<2,>=1->langchain) (4.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from requests<3,>=2->langchain) (2023.5.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
      "Requirement already satisfied: botocore<1.32.0,>=1.31.4 in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from boto3->deeplake) (1.31.4)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from boto3->deeplake) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from boto3->deeplake) (0.6.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from click->deeplake) (0.4.6)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from numcodecs->deeplake) (0.4)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from pathos->deeplake) (1.7.6.6)\n",
      "Requirement already satisfied: dill>=0.3.6 in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from pathos->deeplake) (0.3.6)\n",
      "Requirement already satisfied: pox>=0.3.2 in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from pathos->deeplake) (0.3.2)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from pathos->deeplake) (0.70.14)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from botocore<1.32.0,>=1.31.4->boto3->deeplake) (2.8.2)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.32.0,>=1.31.4->boto3->deeplake) (1.16.0)\n",
      "Installing collected packages: regex, tiktoken\n",
      "Successfully installed regex-2023.6.3 tiktoken-0.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade langchain deeplake openai tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asimj\\.conda\\envs\\langchain\\lib\\site-packages\\deeplake\\util\\check_latest_version.py:32: UserWarning: A newer version of deeplake (3.6.12) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DeepLake\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "\n",
    "root_dir = \"../datasets/contracts2\"\n",
    "\n",
    "docs = []\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    for file in filenames:\n",
    "        if file.endswith(\".txt\") and \"/.venv/\" not in dirpath:\n",
    "            try:\n",
    "                loader = TextLoader(os.path.join(dirpath, file), encoding=\"utf-8\")\n",
    "                docs.extend(loader.load_and_split())\n",
    "            except Exception as e:\n",
    "                pass\n",
    "print(f\"{len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1212, which is longer than the specified 1000\n",
      "Created a chunk of size 1551, which is longer than the specified 1000\n",
      "Created a chunk of size 1001, which is longer than the specified 1000\n",
      "Created a chunk of size 1260, which is longer than the specified 1000\n",
      "Created a chunk of size 1233, which is longer than the specified 1000\n",
      "Created a chunk of size 1285, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(docs)\n",
    "print(f\"{len(texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<class 'openai.api_resources.embedding.Embedding'>, model='text-embedding-ada-002', deployment='text-embedding-ada-002', openai_api_version='', openai_api_base='', openai_api_type='', openai_proxy='', embedding_ctx_length=8191, openai_api_key='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', openai_organization='', allowed_special=set(), disallowed_special='all', chunk_size=1000, max_retries=6, request_timeout=None, headers=None, tiktoken_model_name=None, show_progress_bar=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://commanderastern/polka-code-3', tensors=['embedding', 'id', 'metadata', 'text'])\n",
      "\n",
      "  tensor      htype      shape      dtype  compression\n",
      "  -------    -------    -------    -------  ------- \n",
      " embedding  embedding  (82, 1536)  float32   None   \n",
      "    id        text      (82, 1)      str     None   \n",
      " metadata     json      (82, 1)      str     None   \n",
      "   text       text      (82, 1)      str     None   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langchain.vectorstores.deeplake.DeepLake at 0x28abd012e20>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.vectorstores import DeepLake\n",
    "\n",
    "db = DeepLake.from_documents(\n",
    "    texts, embeddings, dataset_path=f\"hub://commanderastern/polka-code-3\"\n",
    ")\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in hub://commanderastern/polka-code-3 already exists, loading from the storage\n"
     ]
    }
   ],
   "source": [
    "db = DeepLake(\n",
    "    dataset_path=f\"hub://commanderastern/polka-code-3\",\n",
    "    read_only=True,\n",
    "    embedding_function=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()\n",
    "retriever.search_kwargs[\"distance_metric\"] = \"cos\"\n",
    "retriever.search_kwargs[\"fetch_k\"] = 20\n",
    "retriever.search_kwargs[\"maximal_marginal_relevance\"] = True\n",
    "retriever.search_kwargs[\"k\"] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(x):\n",
    "    # filter based on source code\n",
    "    if \"something\" in x[\"text\"].data()[\"value\"]:\n",
    "        return False\n",
    "\n",
    "    # filter based on path e.g. extension\n",
    "    metadata = x[\"metadata\"].data()[\"value\"]\n",
    "    return \"only_this\" in metadata[\"source\"] or \"also_that\" in metadata[\"source\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-3.5-turbo-16k\")  # 'ada' 'gpt-3.5-turbo' 'gpt-4',\n",
    "qa = ConversationalRetrievalChain.from_llm(model, retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> **Question**: A code that store value 1 and 2 and return the sum of the two values \n",
      "\n",
      "**Answer**: Here's an example code that stores the values 1 and 2 and returns their sum:\n",
      "\n",
      "```rust\n",
      "use ink_lang as ink;\n",
      "\n",
      "#[ink::contract]\n",
      "mod value_store {\n",
      "    #[ink(storage)]\n",
      "    pub struct ValueStore {\n",
      "        value1: i32,\n",
      "        value2: i32,\n",
      "    }\n",
      "\n",
      "    impl ValueStore {\n",
      "        #[ink(constructor)]\n",
      "        pub fn new(value1: i32, value2: i32) -> Self {\n",
      "            Self { value1, value2 }\n",
      "        }\n",
      "\n",
      "        #[ink(message)]\n",
      "        pub fn get_sum(&self) -> i32 {\n",
      "            self.value1 + self.value2\n",
      "        }\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "In this code, the `ValueStore` contract has two storage variables `value1` and `value2` of type `i32`. The constructor `new` is used to initialize these values. The `get_sum` message returns the sum of `value1` and `value2`. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"A code that store value 1 and 2 and return the sum of the two values\",\n",
    "]\n",
    "chat_history = []\n",
    "\n",
    "for question in questions:\n",
    "    result = qa({\"question\": question, \"chat_history\": chat_history})\n",
    "    chat_history.append((question, result[\"answer\"]))\n",
    "    print(f\"-> **Question**: {question} \\n\")\n",
    "    print(f\"**Answer**: {result['answer']} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
